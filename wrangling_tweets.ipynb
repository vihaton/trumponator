{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'source/raw_trump_tweets_2.json'\n",
    "\n",
    "df = pd.read_json(open(dir, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datetime.datetime(2018, 9, 26, 10, 57, 30)</td>\n",
       "      <td>Jobless Claims fell to their lowest level in 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datetime.datetime(2018, 9, 26, 10, 54, 59)</td>\n",
       "      <td>Consumer confidence hits an 18 year high, clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datetime.datetime(2018, 9, 26, 2, 55, 20)</td>\n",
       "      <td>The Democrats are playing a high level CON GAM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datetime.datetime(2018, 9, 26, 2, 38, 54)</td>\n",
       "      <td>â€œThese law enforcement people took the law int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datetime.datetime(2018, 9, 25, 22, 6, 33)</td>\n",
       "      <td>73rd Session of the United Nations General Ass...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   created_at  \\\n",
       "0  datetime.datetime(2018, 9, 26, 10, 57, 30)   \n",
       "1  datetime.datetime(2018, 9, 26, 10, 54, 59)   \n",
       "2   datetime.datetime(2018, 9, 26, 2, 55, 20)   \n",
       "3   datetime.datetime(2018, 9, 26, 2, 38, 54)   \n",
       "4   datetime.datetime(2018, 9, 25, 22, 6, 33)   \n",
       "\n",
       "                                                text  \n",
       "0  Jobless Claims fell to their lowest level in 4...  \n",
       "1  Consumer confidence hits an 18 year high, clos...  \n",
       "2  The Democrats are playing a high level CON GAM...  \n",
       "3  â€œThese law enforcement people took the law int...  \n",
       "4  73rd Session of the United Nations General Ass...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      54\n",
       "1     140\n",
       "2     139\n",
       "3     114\n",
       "4      81\n",
       "5     140\n",
       "6     121\n",
       "7     137\n",
       "8     119\n",
       "9      47\n",
       "10     39\n",
       "11     23\n",
       "12    139\n",
       "13    139\n",
       "14    109\n",
       "15    140\n",
       "16     22\n",
       "17     23\n",
       "18    140\n",
       "19    140\n",
       "Name: pre_clean_len, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying out the lengths of the tweets:\n",
    "df['pre_clean_len'] = [len(t) for t in df.text]\n",
    "df['pre_clean_len'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@ricardorossello ......#FakeNews critics are working overtime, but we're getting great marks from the people that truly matter! \\n#PRStrongðŸ‡µðŸ‡·\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying the cleaning with an example tweet first.\n",
    "df.text[3191]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ricardorossello ......#FakeNews critics are working overtime, but we're getting great marks from the people that truly matter! \n",
      "#PRStrongðŸ‡µðŸ‡·\n"
     ]
    }
   ],
   "source": [
    "example1 = BeautifulSoup(df.text[3191], 'lxml')\n",
    "print(example1.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumer confidence hits an 18 year high, close to breaking the all-time record. A big jump from last 8 years. Peopâ€¦ https://t.co/ftDZQ7LWuu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Consumer confidence hits an 18 year high, close to breaking the all-time record. A big jump from last 8 years. Peopâ€¦ https'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing links with \"https\"\n",
    "print(df.text[1])\n",
    "re.sub('https?://[A-Za-z0-9./]+','https',df.text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20    Joint Statement on the United States-Korea Fre...\n",
       "21    Brett Kavanaugh and his wife, Ashley, will be ...\n",
       "22    US-Korea Free Trade Agreement Signing Ceremony...\n",
       "23    It was my great honor to welcome and meet with...\n",
       "24    Today, we commit to fighting the drug epidemic...\n",
       "25    â€œRemarks by President Trump at â€˜Global Call to...\n",
       "26    RT @SCEMD: Now is the time to put safety first...\n",
       "27    Prime Minster @AbeShinzo is coming up to Trump...\n",
       "28    Going to New York. Will be with Prime Minister...\n",
       "29    Tiger is playing great. Looks like a big win c...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was just briefed via phone by @DHSgov @SecNielsen and @FEMA @FEMA_Brock, along with @VP Mike Pence and Chief of Staâ€¦ https://t.co/zh5cE2rfXA'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = df.text[226]\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Was just briefed via phone by @DHSgov @SecNielsen and @FEMA @FEMA_Brock, along with @VP Mike Pence and Chief of Staâ€¦ https://t.co/zh5cE2rfXA'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.replace(u\"\\ufffd\", \"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ricardorossello        FakeNews critics are working overtime  but we re getting great marks from the people that truly matter    PRStrong  '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing special characters, leaving only letters.\n",
    "re.sub(\"[^a-zA-Z]\", \" \", df.text[3191])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual method for cleaning the text\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, 'https', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "\n",
    "    # Do we want to do something for links etc?\n",
    "    \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", stripped)\n",
    "    lower_case = letters_only.lower()\n",
    "\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jobless claims fell to their lowest level in years',\n",
       " 'consumer confidence hits an year high close to breaking the all time record a big jump from last years peop https',\n",
       " 'the democrats are playing a high level con game in their vicious effort to destroy a fine person it is called the https',\n",
       " 'these law enforcement people took the law into their own hands when it came to president trump https',\n",
       " 'rd session of the united nations general assembly unga https',\n",
       " 'consumer confidence rose in september notching its highest level in about years the consumer board s index ro https',\n",
       " 'remarks by president trump at a luncheon hosted by the secretary general of the united nations https',\n",
       " 'remarks by president trump to the rd session of the united nations general assembly https https',\n",
       " 'rush limbaugh to republicans you can kiss the midterms goodbye if you don t get highly qualified kavanaugh approved',\n",
       " 'thank you dr jeffress https']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with small amount of texts\n",
    "testing = df.text[:10]\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner(t))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/h43dehf0WV\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/FXqSWusSTV\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/qZSEifBNaP\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/MgkotGmkJ0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/hIw1AQdRpY\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/LdXQb42Imc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/RzqoiQ4SmD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/zMg2iZgriM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/G0BjCXEnaX\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Vu2b2hhwHu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/54YVC4DDfe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Vh47XjGzpt\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/c79zLeREOA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/H2FiSVxyOF\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/0a25gApyJ6\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6ZG0P6FRs5\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6v90Th0zl1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/3PAVDdfJJr\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/15ibBbf34U\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/wYCNmkkaNR\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/mJtO0AFLus\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/OGqKufBeHn\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/PeF12D2IqJ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/TfRmZA8RWQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/5kIR5EggBp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/TmICRUV9uo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Gm9KE8cHpS\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/E3xvdUGZqa\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/ue5JEZy85v\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/yfwdyUHmn3\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/tJG3KIn2q0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/4OjDqTMEIx\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/8lI2lomGkh\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6VLQYAlcto\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/UM3YJ6lUiD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000  tweets has been processed\n",
      "3000  tweets has been processed\n"
     ]
    }
   ],
   "source": [
    "# Running the tweet_cleaner for the big data\n",
    "print(\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(0, len(df)):\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print(i+1, \" tweets has been processed\")                                                                  \n",
    "    clean_tweet_texts.append(tweet_cleaner(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jobless claims fell to their lowest level in y...</td>\n",
       "      <td>datetime.datetime(2018, 9, 26, 10, 57, 30)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>consumer confidence hits an year high close to...</td>\n",
       "      <td>datetime.datetime(2018, 9, 26, 10, 54, 59)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the democrats are playing a high level con gam...</td>\n",
       "      <td>datetime.datetime(2018, 9, 26, 2, 55, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these law enforcement people took the law into...</td>\n",
       "      <td>datetime.datetime(2018, 9, 26, 2, 38, 54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rd session of the united nations general assem...</td>\n",
       "      <td>datetime.datetime(2018, 9, 25, 22, 6, 33)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  jobless claims fell to their lowest level in y...   \n",
       "1  consumer confidence hits an year high close to...   \n",
       "2  the democrats are playing a high level con gam...   \n",
       "3  these law enforcement people took the law into...   \n",
       "4  rd session of the united nations general assem...   \n",
       "\n",
       "                                    timestamp  \n",
       "0  datetime.datetime(2018, 9, 26, 10, 57, 30)  \n",
       "1  datetime.datetime(2018, 9, 26, 10, 54, 59)  \n",
       "2   datetime.datetime(2018, 9, 26, 2, 55, 20)  \n",
       "3   datetime.datetime(2018, 9, 26, 2, 38, 54)  \n",
       "4   datetime.datetime(2018, 9, 25, 22, 6, 33)  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving clean texts into a dataframe with timestamps\n",
    "clean_df = pd.DataFrame(clean_tweet_texts,columns=['text'])\n",
    "clean_df['timestamp'] = df.created_at\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3199"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
