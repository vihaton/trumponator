{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = '../data/raw/Raw_tweets_DonaldTrump_before_elec.json'\n",
    "after = '../data/raw/Raw_tweets_DonaldTrump_after_elec.json'\n",
    "\n",
    "df_before = pd.read_json(open(before, 'r'))\n",
    "df_after = pd.read_json(open(after, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   created_at  \\\n",
      "0  datetime.datetime(2016, 11, 6, 19, 26, 58)   \n",
      "1   datetime.datetime(2016, 11, 6, 18, 9, 44)   \n",
      "2    datetime.datetime(2016, 11, 6, 17, 6, 8)   \n",
      "3    datetime.datetime(2016, 11, 6, 6, 8, 32)   \n",
      "4       datetime.datetime(2016, 11, 6, 4, 27)   \n",
      "\n",
      "                                                text  \n",
      "0  Thank you Iowa - Get out &amp; #VoteTrumpPence...  \n",
      "1  RT @IvankaTrump: Thank you New Hampshire! ????...  \n",
      "2  Van Jones: ‘There Is A Crack in the Blue Wall’...  \n",
      "3  Great night in Denver, Colorado- thank you! To...  \n",
      "4  RT @DanScavino: Join @realDonaldTrump LIVE in ...  \n"
     ]
    }
   ],
   "source": [
    "# Join dataferames, if more than one, otherwise comment this and just name the dataframe as df.\n",
    "big_df = df_before.append(df_after)\n",
    "df = big_df.reset_index()\n",
    "del df['index']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 19, 26, 58)</td>\n",
       "      <td>Thank you Iowa - Get out &amp;amp; #VoteTrumpPence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 18, 9, 44)</td>\n",
       "      <td>RT @IvankaTrump: Thank you New Hampshire! ????...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 17, 6, 8)</td>\n",
       "      <td>Van Jones: ‘There Is A Crack in the Blue Wall’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 6, 8, 32)</td>\n",
       "      <td>Great night in Denver, Colorado- thank you! To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 4, 27)</td>\n",
       "      <td>RT @DanScavino: Join @realDonaldTrump LIVE in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   created_at  \\\n",
       "0  datetime.datetime(2016, 11, 6, 19, 26, 58)   \n",
       "1   datetime.datetime(2016, 11, 6, 18, 9, 44)   \n",
       "2    datetime.datetime(2016, 11, 6, 17, 6, 8)   \n",
       "3    datetime.datetime(2016, 11, 6, 6, 8, 32)   \n",
       "4       datetime.datetime(2016, 11, 6, 4, 27)   \n",
       "\n",
       "                                                text  \n",
       "0  Thank you Iowa - Get out &amp; #VoteTrumpPence...  \n",
       "1  RT @IvankaTrump: Thank you New Hampshire! ????...  \n",
       "2  Van Jones: ‘There Is A Crack in the Blue Wall’...  \n",
       "3  Great night in Denver, Colorado- thank you! To...  \n",
       "4  RT @DanScavino: Join @realDonaldTrump LIVE in ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual method for cleaning the text\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, 'https', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "\n",
    "    # Do we want to do something for links etc?\n",
    "    \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", stripped)\n",
    "    lower_case = letters_only.lower()\n",
    "\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the cleaned dataframe\n",
    "def make_clean_df(df):\n",
    "    print(\"Cleaning and parsing the tweets...\\n\")\n",
    "    clean_texts = []\n",
    "    for i in range(0, len(df)):\n",
    "        if( (i+1)%1000 == 0 ):\n",
    "            print(i+1, \" tweets has been processed\")                                                                  \n",
    "        clean_texts.append(tweet_cleaner(df['text'][i]))\n",
    "    clean_df = pd.DataFrame(clean_texts,columns=['text'])\n",
    "    clean_df['timestamp'] = df.created_at\n",
    "    clean_df['tweet'] = df.text\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "1000  tweets has been processed\n",
      "2000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/ZQ0osiFEJQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/SmTkLPiBYD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/T5JBFXOz3F\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000  tweets has been processed\n",
      "6000  tweets has been processed\n",
      "7000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://t.co/PtViAyrO4A\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000  tweets has been processed\n",
      "9000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/h43dehf0WV\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/FXqSWusSTV\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/qZSEifBNaP\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/MgkotGmkJ0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/hIw1AQdRpY\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/LdXQb42Imc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/RzqoiQ4SmD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/zMg2iZgriM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/G0BjCXEnaX\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Vu2b2hhwHu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/54YVC4DDfe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Vh47XjGzpt\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/c79zLeREOA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/H2FiSVxyOF\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/0a25gApyJ6\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6ZG0P6FRs5\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6v90Th0zl1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/3PAVDdfJJr\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/15ibBbf34U\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/wYCNmkkaNR\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/mJtO0AFLus\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/OGqKufBeHn\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/PeF12D2IqJ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/TfRmZA8RWQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/5kIR5EggBp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/TmICRUV9uo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Gm9KE8cHpS\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/E3xvdUGZqa\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/ue5JEZy85v\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/yfwdyUHmn3\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/tJG3KIn2q0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/4OjDqTMEIx\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/8lI2lomGkh\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6VLQYAlcto\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/venla/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/UM3YJ6lUiD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000  tweets has been processed\n",
      "13000  tweets has been processed\n",
      "14000  tweets has been processed\n",
      "15000  tweets has been processed\n",
      "16000  tweets has been processed\n",
      "17000  tweets has been processed\n",
      "18000  tweets has been processed\n"
     ]
    }
   ],
   "source": [
    "clean_df = make_clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18473"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the dataframe\n",
    "len(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you iowa get out votetrumppence https https</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 19, 26, 58)</td>\n",
       "      <td>Thank you Iowa - Get out &amp;amp; #VoteTrumpPence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt https thank you new hampshire https</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 18, 9, 44)</td>\n",
       "      <td>RT @IvankaTrump: Thank you New Hampshire! ????...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>van jones there is a crack in the blue wall it...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 17, 6, 8)</td>\n",
       "      <td>Van Jones: ‘There Is A Crack in the Blue Wall’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great night in denver colorado thank you toget...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 6, 8, 32)</td>\n",
       "      <td>Great night in Denver, Colorado- thank you! To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt https join https live in denver colorado vi...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 4, 27)</td>\n",
       "      <td>RT @DanScavino: Join @realDonaldTrump LIVE in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  thank you iowa get out votetrumppence https https   \n",
       "1             rt https thank you new hampshire https   \n",
       "2  van jones there is a crack in the blue wall it...   \n",
       "3  great night in denver colorado thank you toget...   \n",
       "4  rt https join https live in denver colorado vi...   \n",
       "\n",
       "                                    timestamp  \\\n",
       "0  datetime.datetime(2016, 11, 6, 19, 26, 58)   \n",
       "1   datetime.datetime(2016, 11, 6, 18, 9, 44)   \n",
       "2    datetime.datetime(2016, 11, 6, 17, 6, 8)   \n",
       "3    datetime.datetime(2016, 11, 6, 6, 8, 32)   \n",
       "4       datetime.datetime(2016, 11, 6, 4, 27)   \n",
       "\n",
       "                                               tweet  \n",
       "0  Thank you Iowa - Get out &amp; #VoteTrumpPence...  \n",
       "1  RT @IvankaTrump: Thank you New Hampshire! ????...  \n",
       "2  Van Jones: ‘There Is A Crack in the Blue Wall’...  \n",
       "3  Great night in Denver, Colorado- thank you! To...  \n",
       "4  RT @DanScavino: Join @realDonaldTrump LIVE in ...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chenge the filename to write different data\n",
    "with open('../data/clean_tweets/clean_tweets_all.json', 'w') as file:\n",
    "    file.write(clean_df.to_json(orient='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test if the json is readable\n",
    "with open('../data/clean_tweets/clean_tweets_all.json', 'r') as file:\n",
    "    testi = pd.read_json(file, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you iowa get out votetrumppence https https</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 19, 26, 58)</td>\n",
       "      <td>Thank you Iowa - Get out &amp;amp; #VoteTrumpPence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt https thank you new hampshire https</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 18, 9, 44)</td>\n",
       "      <td>RT @IvankaTrump: Thank you New Hampshire! ????...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>van jones there is a crack in the blue wall it...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 17, 6, 8)</td>\n",
       "      <td>Van Jones: ‘There Is A Crack in the Blue Wall’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great night in denver colorado thank you toget...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 6, 8, 32)</td>\n",
       "      <td>Great night in Denver, Colorado- thank you! To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt https join https live in denver colorado vi...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 4, 27)</td>\n",
       "      <td>RT @DanScavino: Join @realDonaldTrump LIVE in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  thank you iowa get out votetrumppence https https   \n",
       "1             rt https thank you new hampshire https   \n",
       "2  van jones there is a crack in the blue wall it...   \n",
       "3  great night in denver colorado thank you toget...   \n",
       "4  rt https join https live in denver colorado vi...   \n",
       "\n",
       "                                    timestamp  \\\n",
       "0  datetime.datetime(2016, 11, 6, 19, 26, 58)   \n",
       "1   datetime.datetime(2016, 11, 6, 18, 9, 44)   \n",
       "2    datetime.datetime(2016, 11, 6, 17, 6, 8)   \n",
       "3    datetime.datetime(2016, 11, 6, 6, 8, 32)   \n",
       "4       datetime.datetime(2016, 11, 6, 4, 27)   \n",
       "\n",
       "                                               tweet  \n",
       "0  Thank you Iowa - Get out &amp; #VoteTrumpPence...  \n",
       "1  RT @IvankaTrump: Thank you New Hampshire! ????...  \n",
       "2  Van Jones: ‘There Is A Crack in the Blue Wall’...  \n",
       "3  Great night in Denver, Colorado- thank you! To...  \n",
       "4  RT @DanScavino: Join @realDonaldTrump LIVE in ...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'to_timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-70fcbc8299fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'to_timestamp'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        datetime.datetime(2016, 11, 6, 19, 26, 58)\n",
       "1         datetime.datetime(2016, 11, 6, 18, 9, 44)\n",
       "2          datetime.datetime(2016, 11, 6, 17, 6, 8)\n",
       "3          datetime.datetime(2016, 11, 6, 6, 8, 32)\n",
       "4             datetime.datetime(2016, 11, 6, 4, 27)\n",
       "5          datetime.datetime(2016, 11, 6, 2, 3, 20)\n",
       "6         datetime.datetime(2016, 11, 6, 0, 20, 16)\n",
       "7         datetime.datetime(2016, 11, 6, 0, 19, 18)\n",
       "8        datetime.datetime(2016, 11, 5, 21, 46, 34)\n",
       "9        datetime.datetime(2016, 11, 5, 21, 39, 44)\n",
       "10        datetime.datetime(2016, 11, 5, 21, 38, 1)\n",
       "11       datetime.datetime(2016, 11, 5, 21, 27, 32)\n",
       "12       datetime.datetime(2016, 11, 5, 20, 13, 34)\n",
       "13        datetime.datetime(2016, 11, 5, 20, 6, 21)\n",
       "14        datetime.datetime(2016, 11, 5, 16, 45, 5)\n",
       "15       datetime.datetime(2016, 11, 5, 13, 33, 10)\n",
       "16        datetime.datetime(2016, 11, 5, 2, 52, 56)\n",
       "17       datetime.datetime(2016, 11, 4, 23, 57, 37)\n",
       "18       datetime.datetime(2016, 11, 4, 23, 50, 57)\n",
       "19       datetime.datetime(2016, 11, 4, 23, 31, 28)\n",
       "20       datetime.datetime(2016, 11, 4, 23, 14, 59)\n",
       "21       datetime.datetime(2016, 11, 4, 20, 33, 12)\n",
       "22        datetime.datetime(2016, 11, 4, 19, 7, 20)\n",
       "23       datetime.datetime(2016, 11, 4, 18, 56, 15)\n",
       "24       datetime.datetime(2016, 11, 4, 18, 46, 42)\n",
       "25       datetime.datetime(2016, 11, 4, 16, 28, 36)\n",
       "26       datetime.datetime(2016, 11, 4, 16, 26, 19)\n",
       "27       datetime.datetime(2016, 11, 4, 16, 17, 22)\n",
       "28       datetime.datetime(2016, 11, 4, 15, 32, 31)\n",
       "29         datetime.datetime(2016, 11, 4, 2, 35, 8)\n",
       "                            ...                    \n",
       "13102     datetime.datetime(2017, 10, 4, 0, 25, 34)\n",
       "13103      datetime.datetime(2017, 10, 4, 0, 24, 2)\n",
       "13104     datetime.datetime(2017, 10, 4, 0, 20, 48)\n",
       "13105     datetime.datetime(2017, 10, 3, 23, 2, 51)\n",
       "13106    datetime.datetime(2017, 10, 3, 21, 59, 58)\n",
       "13107    datetime.datetime(2017, 10, 3, 21, 22, 19)\n",
       "13108    datetime.datetime(2017, 10, 3, 11, 40, 47)\n",
       "13109    datetime.datetime(2017, 10, 2, 11, 11, 37)\n",
       "13110     datetime.datetime(2017, 10, 2, 1, 22, 34)\n",
       "13111     datetime.datetime(2017, 10, 1, 19, 1, 19)\n",
       "13112    datetime.datetime(2017, 10, 1, 14, 31, 15)\n",
       "13113    datetime.datetime(2017, 10, 1, 14, 30, 59)\n",
       "13114    datetime.datetime(2017, 10, 1, 12, 30, 17)\n",
       "13115    datetime.datetime(2017, 10, 1, 12, 26, 26)\n",
       "13116    datetime.datetime(2017, 10, 1, 12, 22, 14)\n",
       "13117          datetime.datetime(2017, 10, 1, 2, 8)\n",
       "13118    datetime.datetime(2017, 9, 30, 23, 24, 18)\n",
       "13119    datetime.datetime(2017, 9, 30, 22, 46, 47)\n",
       "13120    datetime.datetime(2017, 9, 30, 22, 26, 55)\n",
       "13121     datetime.datetime(2017, 9, 30, 22, 15, 2)\n",
       "13122    datetime.datetime(2017, 9, 30, 20, 37, 10)\n",
       "13123    datetime.datetime(2017, 9, 30, 19, 57, 29)\n",
       "13124    datetime.datetime(2017, 9, 30, 19, 56, 46)\n",
       "13125    datetime.datetime(2017, 9, 30, 19, 55, 20)\n",
       "13126    datetime.datetime(2017, 9, 30, 19, 53, 51)\n",
       "13127    datetime.datetime(2017, 9, 30, 19, 43, 54)\n",
       "13128    datetime.datetime(2017, 9, 30, 19, 30, 17)\n",
       "13129    datetime.datetime(2017, 9, 30, 19, 19, 36)\n",
       "13130     datetime.datetime(2017, 9, 30, 18, 4, 59)\n",
       "13131      datetime.datetime(2017, 9, 30, 12, 7, 9)\n",
       "Name: timestamp, Length: 13132, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
