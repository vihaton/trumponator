{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = '../data/raw/Raw_tweets_DonaldTrump_before_elec.json'\n",
    "after = '../data/raw/Raw_tweets_DonaldTrump_after_elec.json'\n",
    "\n",
    "df_before = pd.read_json(open(before, 'r'))\n",
    "df_after = pd.read_json(open(after, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   created_at  \\\n",
      "0  datetime.datetime(2016, 11, 6, 19, 26, 58)   \n",
      "1   datetime.datetime(2016, 11, 6, 18, 9, 44)   \n",
      "2    datetime.datetime(2016, 11, 6, 17, 6, 8)   \n",
      "3    datetime.datetime(2016, 11, 6, 6, 8, 32)   \n",
      "4       datetime.datetime(2016, 11, 6, 4, 27)   \n",
      "\n",
      "                                                text  \n",
      "0  Thank you Iowa - Get out &amp; #VoteTrumpPence...  \n",
      "1  RT @IvankaTrump: Thank you New Hampshire! ????...  \n",
      "2  Van Jones: ‘There Is A Crack in the Blue Wall’...  \n",
      "3  Great night in Denver, Colorado- thank you! To...  \n",
      "4  RT @DanScavino: Join @realDonaldTrump LIVE in ...  \n"
     ]
    }
   ],
   "source": [
    "# Join dataferames, if more than one, otherwise comment this and just name the dataframe as df.\n",
    "big_df = df_before.append(df_after)\n",
    "df = big_df.reset_index()\n",
    "del df['index']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 19, 26, 58)</td>\n",
       "      <td>Thank you Iowa - Get out &amp;amp; #VoteTrumpPence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 18, 9, 44)</td>\n",
       "      <td>RT @IvankaTrump: Thank you New Hampshire! ????...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 17, 6, 8)</td>\n",
       "      <td>Van Jones: ‘There Is A Crack in the Blue Wall’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 6, 8, 32)</td>\n",
       "      <td>Great night in Denver, Colorado- thank you! To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datetime.datetime(2016, 11, 6, 4, 27)</td>\n",
       "      <td>RT @DanScavino: Join @realDonaldTrump LIVE in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   created_at  \\\n",
       "0  datetime.datetime(2016, 11, 6, 19, 26, 58)   \n",
       "1   datetime.datetime(2016, 11, 6, 18, 9, 44)   \n",
       "2    datetime.datetime(2016, 11, 6, 17, 6, 8)   \n",
       "3    datetime.datetime(2016, 11, 6, 6, 8, 32)   \n",
       "4       datetime.datetime(2016, 11, 6, 4, 27)   \n",
       "\n",
       "                                                text  \n",
       "0  Thank you Iowa - Get out &amp; #VoteTrumpPence...  \n",
       "1  RT @IvankaTrump: Thank you New Hampshire! ????...  \n",
       "2  Van Jones: ‘There Is A Crack in the Blue Wall’...  \n",
       "3  Great night in Denver, Colorado- thank you! To...  \n",
       "4  RT @DanScavino: Join @realDonaldTrump LIVE in ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual method for cleaning the text\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, 'https', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "\n",
    "    # Do we want to do something for links etc?\n",
    "    \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", stripped)\n",
    "    lower_case = letters_only.lower()\n",
    "\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the cleaned dataframe\n",
    "def make_clean_df(df):\n",
    "    print(\"Cleaning and parsing the tweets...\\n\")\n",
    "    clean_texts = []\n",
    "    for i in range(0, len(df)):\n",
    "        if( (i+1)%1000 == 0 ):\n",
    "            print(i+1, \" tweets has been processed\")                                                                  \n",
    "        clean_texts.append(tweet_cleaner(df['text'][i]))\n",
    "    clean_df = pd.DataFrame(clean_texts,columns=['text'])\n",
    "    clean_df['timestamp'] = df.created_at\n",
    "    clean_df['tweet'] = df.text\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "1000  tweets has been processed\n",
      "2000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/ZQ0osiFEJQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/SmTkLPiBYD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000  tweets has been processed\n",
      "4000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/T5JBFXOz3F\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000  tweets has been processed\n",
      "6000  tweets has been processed\n",
      "7000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"http://t.co/PtViAyrO4A\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000  tweets has been processed\n",
      "9000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/h43dehf0WV\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/FXqSWusSTV\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/qZSEifBNaP\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/MgkotGmkJ0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/hIw1AQdRpY\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/LdXQb42Imc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/RzqoiQ4SmD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/zMg2iZgriM\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/G0BjCXEnaX\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Vu2b2hhwHu\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/54YVC4DDfe\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Vh47XjGzpt\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/c79zLeREOA\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/H2FiSVxyOF\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/0a25gApyJ6\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6ZG0P6FRs5\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6v90Th0zl1\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/3PAVDdfJJr\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/15ibBbf34U\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/wYCNmkkaNR\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/mJtO0AFLus\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/OGqKufBeHn\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/PeF12D2IqJ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/TfRmZA8RWQ\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/5kIR5EggBp\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/TmICRUV9uo\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/Gm9KE8cHpS\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/E3xvdUGZqa\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/ue5JEZy85v\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/yfwdyUHmn3\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/tJG3KIn2q0\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/4OjDqTMEIx\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/8lI2lomGkh\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000  tweets has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/6VLQYAlcto\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "/home/vili/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:282: UserWarning: \"https://t.co/UM3YJ6lUiD\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000  tweets has been processed\n",
      "13000  tweets has been processed\n",
      "14000  tweets has been processed\n",
      "15000  tweets has been processed\n",
      "16000  tweets has been processed\n",
      "17000  tweets has been processed\n",
      "18000  tweets has been processed\n"
     ]
    }
   ],
   "source": [
    "clean_df = make_clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18473"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the dataframe\n",
    "len(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you iowa get out votetrumppence https https</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 19, 26, 58)</td>\n",
       "      <td>Thank you Iowa - Get out &amp;amp; #VoteTrumpPence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt https thank you new hampshire https</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 18, 9, 44)</td>\n",
       "      <td>RT @IvankaTrump: Thank you New Hampshire! ????...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>van jones there is a crack in the blue wall it...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 17, 6, 8)</td>\n",
       "      <td>Van Jones: ‘There Is A Crack in the Blue Wall’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great night in denver colorado thank you toget...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 6, 8, 32)</td>\n",
       "      <td>Great night in Denver, Colorado- thank you! To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt https join https live in denver colorado vi...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 4, 27)</td>\n",
       "      <td>RT @DanScavino: Join @realDonaldTrump LIVE in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  thank you iowa get out votetrumppence https https   \n",
       "1             rt https thank you new hampshire https   \n",
       "2  van jones there is a crack in the blue wall it...   \n",
       "3  great night in denver colorado thank you toget...   \n",
       "4  rt https join https live in denver colorado vi...   \n",
       "\n",
       "                                    timestamp  \\\n",
       "0  datetime.datetime(2016, 11, 6, 19, 26, 58)   \n",
       "1   datetime.datetime(2016, 11, 6, 18, 9, 44)   \n",
       "2    datetime.datetime(2016, 11, 6, 17, 6, 8)   \n",
       "3    datetime.datetime(2016, 11, 6, 6, 8, 32)   \n",
       "4       datetime.datetime(2016, 11, 6, 4, 27)   \n",
       "\n",
       "                                               tweet  \n",
       "0  Thank you Iowa - Get out &amp; #VoteTrumpPence...  \n",
       "1  RT @IvankaTrump: Thank you New Hampshire! ????...  \n",
       "2  Van Jones: ‘There Is A Crack in the Blue Wall’...  \n",
       "3  Great night in Denver, Colorado- thank you! To...  \n",
       "4  RT @DanScavino: Join @realDonaldTrump LIVE in ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chenge the filename to write different data\n",
    "with open('../data/clean_tweets/clean_tweets_all.json', 'w') as file:\n",
    "    file.write(clean_df.to_json(orient='index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test if the json is readable\n",
    "with open('../data/clean_tweets/clean_tweets_all.json', 'r') as file:\n",
    "    testi = pd.read_json(file, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank you iowa get out votetrumppence https https</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 19, 26, 58)</td>\n",
       "      <td>Thank you Iowa - Get out &amp;amp; #VoteTrumpPence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt https thank you new hampshire https</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 18, 9, 44)</td>\n",
       "      <td>RT @IvankaTrump: Thank you New Hampshire! ????...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>van jones there is a crack in the blue wall it...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 17, 6, 8)</td>\n",
       "      <td>Van Jones: ‘There Is A Crack in the Blue Wall’...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>great night in denver colorado thank you toget...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 6, 8, 32)</td>\n",
       "      <td>Great night in Denver, Colorado- thank you! To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt https join https live in denver colorado vi...</td>\n",
       "      <td>datetime.datetime(2016, 11, 6, 4, 27)</td>\n",
       "      <td>RT @DanScavino: Join @realDonaldTrump LIVE in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  thank you iowa get out votetrumppence https https   \n",
       "1             rt https thank you new hampshire https   \n",
       "2  van jones there is a crack in the blue wall it...   \n",
       "3  great night in denver colorado thank you toget...   \n",
       "4  rt https join https live in denver colorado vi...   \n",
       "\n",
       "                                    timestamp  \\\n",
       "0  datetime.datetime(2016, 11, 6, 19, 26, 58)   \n",
       "1   datetime.datetime(2016, 11, 6, 18, 9, 44)   \n",
       "2    datetime.datetime(2016, 11, 6, 17, 6, 8)   \n",
       "3    datetime.datetime(2016, 11, 6, 6, 8, 32)   \n",
       "4       datetime.datetime(2016, 11, 6, 4, 27)   \n",
       "\n",
       "                                               tweet  \n",
       "0  Thank you Iowa - Get out &amp; #VoteTrumpPence...  \n",
       "1  RT @IvankaTrump: Thank you New Hampshire! ????...  \n",
       "2  Van Jones: ‘There Is A Crack in the Blue Wall’...  \n",
       "3  Great night in Denver, Colorado- thank you! To...  \n",
       "4  RT @DanScavino: Join @realDonaldTrump LIVE in ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
